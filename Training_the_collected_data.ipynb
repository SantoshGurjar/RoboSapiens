{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a490805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20e38519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing object the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# First convolution layer and pooing\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape=(64, 64, 1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Second convolution layer and pooling\n",
    "classifier.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adding a fully connected layer\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=6, activation='softmax')) # softmax for more than 2\n",
    "\n",
    "#intotal 2 convolution layers havebeen taken and then a hidden neural dense network has been taken and activation\n",
    "#functiion relu has been considered to increase the efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4269e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # categorical_crossentropy for more than 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4d079e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "892bd905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#increasing the train and test data set just by varring the already stored image \n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39034dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2507 images belonging to 6 classes.\n",
      "Found 550 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "#Taking the path to a directory and generating augmented/normalized data.\n",
    "X_train = train_datagen.flow_from_directory('data/train',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=5,\n",
    "                                                 color_mode='grayscale',\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "X_test = test_datagen.flow_from_directory('data/test',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=5,\n",
    "                                            color_mode='grayscale',\n",
    "                                            class_mode='categorical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cbf73801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "502/600 [========================>.....] - ETA: 4s - loss: 0.4848 - accuracy: 0.8026WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 6000 batches). You may need to use the repeat() function when building your dataset.\n",
      "600/600 [==============================] - 31s 40ms/step - loss: 0.4848 - accuracy: 0.8026 - val_loss: 0.6490 - val_accuracy: 0.7800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1971807de20>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(\n",
    "        X_train,\n",
    "        steps_per_epoch=600, # No of images in training set\n",
    "        epochs=10,\n",
    "        validation_data=X_test,\n",
    "        validation_steps=30)# No of images in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b183f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model_json = classifier.to_json()\n",
    "with open(\"model-bw.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "classifier.save_weights('model-bw.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e1a03b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
